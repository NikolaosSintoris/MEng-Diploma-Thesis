{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50 pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Download the ResNet50 pre-trained model.\n",
    "resnet50_model = models.resnet50(pretrained = True) # pretrained: If True, returns a model pre-trained on ImageNet.\n",
    "print(resnet50_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dict = {\n",
    "    \"layer 1\": -5,\n",
    "    \"layer 2\": -4,\n",
    "    \"layer 3\": -3,\n",
    "    \"layer 4\": -2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that its output is the output of the chosen intermediate layer from resnet50 model.\n",
    "resnet50_intermediate_layer_model = nn.Sequential(*list(resnet50_model.children())[:layers_dict[\"layer 2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50 MoCo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the pre-trained weights and save them in a dictionairy.\n",
    "# The directory where my checkpoints are saved.\n",
    "checkpoints_directory = r\"C:\\Nikolaos Sintoris\\Education\\MEng CSE - UOI\\Diploma Thesis\\Checkpoints\"\n",
    "\n",
    "moco_checkpoint = torch.load(checkpoints_directory + '\\\\moco_v2_800ep_pretrain.pth.tar')\n",
    "moco_checkpoint_dict = moco_checkpoint['state_dict']\n",
    "\n",
    "# Rename moco pre-trained keys in order to match the ResNet50 keys.\n",
    "for k in list(moco_checkpoint_dict.keys()):\n",
    "    # retain only encoder_q up to before the embedding layer\n",
    "    if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "        # remove prefix\n",
    "        moco_checkpoint_dict[k[len(\"module.encoder_q.\"):]] = moco_checkpoint_dict[k]\n",
    "    # delete renamed or unused k\n",
    "    del moco_checkpoint_dict[k]\n",
    "    \n",
    "# Download the ResNet50 model.\n",
    "resnet50_moco_model = models.resnet50(pretrained = False)\n",
    "\n",
    "# Load the pre-trained weights from MoCo.\n",
    "resnet50_moco_model.load_state_dict(moco_checkpoint_dict, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that its output is the output of the chosen intermediate layer from resnet50 MoCo model.\n",
    "resnet50_moco_intermediate_layer_model = nn.Sequential(*list(resnet50_moco_model.children())[:layers_dict[\"layer 2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet50 SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the pre-trained weights and save them in a dictionairy.\n",
    "# The directory where my checkpoints are saved.\n",
    "checkpoints_directory = r\"C:\\Nikolaos Sintoris\\Education\\MEng CSE - UOI\\Diploma Thesis\\Checkpoints\"\n",
    "\n",
    "simclr_checkpoint = torch.load(checkpoints_directory + '\\\\checkpoint_0040.pth.tar')\n",
    "simclr_checkpoint_dict = simclr_checkpoint['state_dict']\n",
    "\n",
    "# Rename moco pre-trained keys in order to match the ResNet50 keys.\n",
    "for k in list(simclr_checkpoint_dict.keys()):\n",
    "    # retain only encoder_q up to before the embedding layer\n",
    "    if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
    "        # remove prefix\n",
    "        simclr_checkpoint_dict[k[len(\"backbone.\"):]] = simclr_checkpoint_dict[k]\n",
    "    # delete renamed or unused k\n",
    "    del simclr_checkpoint_dict[k]\n",
    "\n",
    "# Download the ResNet50 model.\n",
    "resnet50_simclr_model = models.resnet50(pretrained = False)\n",
    "\n",
    "# Load the pre-trained weights from SimCLR.\n",
    "resnet50_simclr_model.load_state_dict(simclr_checkpoint_dict, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model that its output is the output of the chosen intermediate layer from resnet50 SimCLR model.\n",
    "resnet50_simclr_intermediate_layer_model = nn.Sequential(*list(resnet50_simclr_model.children())[:layers_dict[\"layer 2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image to 224x224 because VGG16 takes an input image of this size.\n",
    "# transforms.Compose(): Composes several transforms together.   \n",
    "# transforms.Resize(): Resize the input image to the given size.    \n",
    "# transforms.ToTensor(): Convert a PIL Image or numpy.ndarray to tensor.    \n",
    "# transforms.Normalize(): Normalize a tensor image with mean and standard deviation for n channels.\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagePooling(my_tensor):\n",
    "    temp_tensor = nn.AvgPool2d(my_tensor.shape[-1])(my_tensor)\n",
    "    final_tensor = temp_tensor[:, :, -1]# Convert from 4D to 3D tensor.\n",
    "    return final_tensor.T # Transpose the tensor in order to have a vector.\n",
    "\n",
    "def averagePoolingNonSquare(my_tensor):\n",
    "    temp_tensor = nn.AvgPool2d((my_tensor.shape[-2], my_tensor.shape[-1]))(my_tensor)\n",
    "    final_tensor = temp_tensor[:, :, -1]# Convert from 4D to 3D tensor.\n",
    "    return final_tensor.T # Transpose the tensor in order to have a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary that has all the possible categories.\n",
    "labels_dict = {\n",
    "    \"0\": 0,\n",
    "    \"1\": 1,\n",
    "    \"2\": 2\n",
    "}\n",
    "\n",
    "# Set the directory that all of my data is saved.\n",
    "train_dataset_directory = r\"C:\\Nikolaos Sintoris\\Education\\MEng CSE - UOI\\Diploma Thesis\\Scanning\\Train dataset\"\n",
    "\n",
    "# About ImageFolder():\n",
    "# Images should be sorted into folders. All the pictures of AK should be in one folder, \n",
    "# all the pictures of NORM should be in another etc.\n",
    "# root: Root directory path\n",
    "# transform: A function/transform that takes in an PIL image and returns a transformed version\n",
    "training_dataset = torchvision.datasets.ImageFolder(root = train_dataset_directory , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data:  8095\n",
      "Number of validation data:  3469\n"
     ]
    }
   ],
   "source": [
    "# Save the number of training, validation and test data.\n",
    "number_of_training_data = len(training_dataset)\n",
    "\n",
    "# Validation data is 30% of training data.\n",
    "number_of_validation_data = number_of_training_data - round(number_of_training_data * 0.7)\n",
    "number_of_training_data = number_of_training_data - number_of_validation_data\n",
    "\n",
    "# Create a DataLoader, which can split the training data into batches of size 1, while training. \n",
    "# shuffle=True: ensure that the batches generated in each epoch are different.\n",
    "trainloader = torch.utils.data.DataLoader(training_dataset, batch_size = 1, shuffle = True)   \n",
    "\n",
    "print(\"Number of training data: \", number_of_training_data)\n",
    "print(\"Number of validation data: \", number_of_validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50-MoCo\n",
      "\tTrain Data: \n",
      "\t\tTraining data shape:  torch.Size([8095, 512])\n",
      "\t\tTraining labels shape:  torch.Size([8095])\n",
      "\tValidation Data: \n",
      "\t\tValidation data shape:  torch.Size([3469, 512])\n",
      "\t\tValidation labels shape:  torch.Size([3469])\n",
      "ResNet50-SimCLR\n",
      "\tTrain Data: \n",
      "\t\tTraining data shape:  torch.Size([8095, 512])\n",
      "\t\tTraining labels shape:  torch.Size([8095])\n",
      "\tValidation Data: \n",
      "\t\tValidation data shape:  torch.Size([3469, 512])\n",
      "\t\tValidation labels shape:  torch.Size([3469])\n"
     ]
    }
   ],
   "source": [
    "# training_data: A torch tensor that has the output of resnet50_layer4 model from the training images.\n",
    "# actual_training_labels: A torch tensor that has the actual labels of the training images.\n",
    "# Same for validation.\n",
    "#classifier_training_data = torch.randn(number_of_training_data, 512, dtype = torch.float)   \n",
    "actual_training_labels = torch.tensor(np.arange(number_of_training_data))\n",
    "actual_training_labels = actual_training_labels.type(torch.LongTensor)\n",
    "\n",
    "#classifier_validation_data = torch.randn(number_of_validation_data, 512, dtype = torch.float)   \n",
    "actual_validation_labels = torch.tensor(np.arange(number_of_validation_data))\n",
    "actual_validation_labels = actual_validation_labels.type(torch.LongTensor)\n",
    "\n",
    "\n",
    "moco_training_data = torch.randn(number_of_training_data, 512, dtype = torch.float)   \n",
    "moco_validation_data = torch.randn(number_of_validation_data, 512, dtype = torch.float)     \n",
    "\n",
    "simclr_training_data = torch.randn(number_of_training_data, 512, dtype = torch.float)   \n",
    "simclr_validation_data = torch.randn(number_of_validation_data, 512, dtype = torch.float)\n",
    "\n",
    "\n",
    "resnet50_intermediate_layer_model.eval()\n",
    "resnet50_moco_intermediate_layer_model.eval()\n",
    "resnet50_simclr_intermediate_layer_model.eval()\n",
    "\n",
    "train_index = 0\n",
    "validation_index = 0\n",
    "for image, label in trainloader:\n",
    "    with torch.no_grad():\n",
    "        # Take the output from layer_1, then apply average poooling and store it to the training_data.\n",
    "        #classifier_a = resnet50_intermediate_layer_model(image)\n",
    "        #classifier_b = classifier_a[-1, :, :, :] # Convert from 4D to 3D tensor.\n",
    "        #classifier_output = averagePooling(classifier_b)\n",
    "        moco_a = resnet50_moco_intermediate_layer_model(image)\n",
    "        moco_b = moco_a[-1, :, :, :] # Convert from 4D to 3D tensor.\n",
    "        moco_output = averagePooling(moco_b)\n",
    "        simclr_a = resnet50_simclr_intermediate_layer_model(image)\n",
    "        simclr_b = simclr_a[-1, :, :, :] # Convert from 4D to 3D tensor.\n",
    "        simclr_output = averagePoolingNonSquare(simclr_b)\n",
    "\n",
    "    # The last 30% of training data, store it as validation data.\n",
    "    if(train_index < number_of_training_data):\n",
    "        #classifier_training_data[train_index] = classifier_output\n",
    "        moco_training_data[train_index] = moco_output\n",
    "        simclr_training_data[train_index] = simclr_output\n",
    "\n",
    "        # Create a torch tensor that has the actual labels of the training set.\n",
    "        str_label = str(label.item())\n",
    "        actual_training_labels[train_index] = labels_dict[str_label]\n",
    "\n",
    "        train_index = train_index + 1\n",
    "    else:\n",
    "        #classifier_validation_data[validation_index] = classifier_output\n",
    "        moco_validation_data[validation_index] = moco_output\n",
    "        simclr_validation_data[validation_index] = simclr_output\n",
    "\n",
    "        # Create a torch tensor that has the actual labels of the validation set.\n",
    "        str_label = str(label.item())\n",
    "        actual_validation_labels[validation_index] = labels_dict[str_label]\n",
    "\n",
    "        validation_index = validation_index + 1\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\n",
    "print(\"ResNet50-Classifier\")\n",
    "print(\"\\tTrain Data: \")\n",
    "print(\"\\t\\tTraining data shape: \", classifier_training_data.shape)\n",
    "print(\"\\t\\tTraining labels shape: \", actual_training_labels.shape)\n",
    "\n",
    "print(\"\\tValidation Data: \")\n",
    "print(\"\\t\\tValidation data shape: \", classifier_validation_data.shape)\n",
    "print(\"\\t\\tValidation labels shape: \", actual_validation_labels.shape)\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\n",
    "print(\"ResNet50-MoCo\")\n",
    "print(\"\\tTrain Data: \")\n",
    "print(\"\\t\\tTraining data shape: \", moco_training_data.shape)\n",
    "print(\"\\t\\tTraining labels shape: \", actual_training_labels.shape)\n",
    "\n",
    "print(\"\\tValidation Data: \")\n",
    "print(\"\\t\\tValidation data shape: \", moco_validation_data.shape)\n",
    "print(\"\\t\\tValidation labels shape: \", actual_validation_labels.shape)\n",
    "\n",
    "print(\"ResNet50-SimCLR\")\n",
    "print(\"\\tTrain Data: \")\n",
    "print(\"\\t\\tTraining data shape: \", simclr_training_data.shape)\n",
    "print(\"\\t\\tTraining labels shape: \", actual_training_labels.shape)\n",
    "\n",
    "print(\"\\tValidation Data: \")\n",
    "print(\"\\t\\tValidation data shape: \", simclr_validation_data.shape)\n",
    "print(\"\\t\\tValidation labels shape: \", actual_validation_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert tensors to np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensors to numpy arrays in order to store them in csv files.\n",
    "#classifier_training_data_np = classifier_training_data.numpy()\n",
    "actual_training_labels_np = actual_training_labels.numpy()\n",
    "\n",
    "#classifier_validation_data_np = classifier_validation_data.numpy()\n",
    "actual_validation_labels_np = actual_validation_labels.numpy()\n",
    "\n",
    "moco_training_data_np = moco_training_data.numpy()\n",
    "moco_validation_data_np = moco_validation_data.numpy()\n",
    "\n",
    "simclr_training_data_np = simclr_training_data.numpy()\n",
    "simclr_validation_data_np = simclr_validation_data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store embeddings in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Store the embeddings in csv files.\n",
    "#classifier_embeddings_directory = r\"C:\\Nikolaos Sintoris\\Education\\MEng CSE - UOI\\Diploma Thesis\\Scanning\\Train results\\ResNet50 Classifier\\Layer 1\\Embeddings\"\n",
    "\n",
    "#if not os.path.exists(classifier_embeddings_directory):\n",
    "#    os.makedirs(classifier_embeddings_directory)\n",
    "\n",
    "moco_embeddings_directory = r\"C:\\Nikolaos Sintoris\\Education\\MEng CSE - UOI\\Diploma Thesis\\Scanning\\Train results\\ResNet50 MoCo\\Layer 2\\Embeddings\"\n",
    "\n",
    "if not os.path.exists(moco_embeddings_directory):\n",
    "    os.makedirs(moco_embeddings_directory)\n",
    "\n",
    "simclr_embeddings_directory = r\"C:\\Nikolaos Sintoris\\Education\\MEng CSE - UOI\\Diploma Thesis\\Scanning\\Train results\\ResNet50 SimCLR\\Layer 2\\Embeddings\"\n",
    "\n",
    "if not os.path.exists(simclr_embeddings_directory):\n",
    "    os.makedirs(simclr_embeddings_directory)\n",
    "\n",
    "case_data = [\"training_data\", \"actual_training_labels\", \"validation_data\", \"actual_validation_labels\"]\n",
    "\n",
    "#classifier_case_data_np_dict = {\n",
    "#    \"training_data\": classifier_training_data_np,\n",
    "#    \"actual_training_labels\": actual_training_labels_np,\n",
    "#    \"validation_data\": classifier_validation_data_np,\n",
    "#    \"actual_validation_labels\": actual_validation_labels_np\n",
    "#}\n",
    "\n",
    "\n",
    "moco_case_data_np_dict = {\n",
    "    \"training_data\": moco_training_data_np,\n",
    "    \"actual_training_labels\": actual_training_labels_np,\n",
    "    \"validation_data\": moco_validation_data_np,\n",
    "    \"actual_validation_labels\": actual_validation_labels_np\n",
    "}\n",
    "\n",
    "simclr_case_data_np_dict = {\n",
    "    \"training_data\": simclr_training_data_np,\n",
    "    \"actual_training_labels\": actual_training_labels_np,\n",
    "    \"validation_data\": simclr_validation_data_np,\n",
    "    \"actual_validation_labels\": actual_validation_labels_np\n",
    "}\n",
    "\n",
    "case_data_csv_dict = {\n",
    "    \"training_data\": \"\\\\training_data.csv\",\n",
    "    \"actual_training_labels\": \"\\\\actual_training_labels.csv\",\n",
    "    \"validation_data\": \"\\\\validation_data.csv\",\n",
    "    \"actual_validation_labels\": \"\\\\actual_validation_labels.csv\"\n",
    "}\n",
    "\n",
    "# Save every numpy array to a different csv file.\n",
    "\"\"\"\"\"\"\"\"\"\n",
    "for current_data in case_data:\n",
    "    np.savetxt(classifier_embeddings_directory + case_data_csv_dict[current_data], classifier_case_data_np_dict[current_data], delimiter = ',')\n",
    "\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "for current_data in case_data:\n",
    "    np.savetxt(moco_embeddings_directory + case_data_csv_dict[current_data], moco_case_data_np_dict[current_data], delimiter = ',')\n",
    "\n",
    "for current_data in case_data:\n",
    "    np.savetxt(simclr_embeddings_directory + case_data_csv_dict[current_data], simclr_case_data_np_dict[current_data], delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
